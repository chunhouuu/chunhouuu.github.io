<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>How to Analyze A/B Tests Results? | Notes from Tino</title>
<meta name="keywords" content="">
<meta name="description" content="What is A/B tests? Image that you are running an e-commerce platform which is an otter dolls specialty stores. You find that around 20% of users cancel the transactions in the very last step of the checkout flow (Fig. 1-a). To improve the checkout completion rate, you come up with an idea that adding an adorable otter image (Fig. 1-b), which assumes that image makes users have stronger desire to get the item.">
<meta name="author" content="">
<link rel="canonical" href="https://chunhouuu.github.io/posts/abtest-analysis/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css" integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://chunhouuu.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://chunhouuu.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://chunhouuu.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://chunhouuu.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://chunhouuu.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="How to Analyze A/B Tests Results?" />
<meta property="og:description" content="What is A/B tests? Image that you are running an e-commerce platform which is an otter dolls specialty stores. You find that around 20% of users cancel the transactions in the very last step of the checkout flow (Fig. 1-a). To improve the checkout completion rate, you come up with an idea that adding an adorable otter image (Fig. 1-b), which assumes that image makes users have stronger desire to get the item." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chunhouuu.github.io/posts/abtest-analysis/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-13T22:58:34&#43;08:00" />
<meta property="article:modified_time" content="2022-06-13T22:58:34&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="How to Analyze A/B Tests Results?"/>
<meta name="twitter:description" content="What is A/B tests? Image that you are running an e-commerce platform which is an otter dolls specialty stores. You find that around 20% of users cancel the transactions in the very last step of the checkout flow (Fig. 1-a). To improve the checkout completion rate, you come up with an idea that adding an adorable otter image (Fig. 1-b), which assumes that image makes users have stronger desire to get the item."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://chunhouuu.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "How to Analyze A/B Tests Results?",
      "item": "https://chunhouuu.github.io/posts/abtest-analysis/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "How to Analyze A/B Tests Results?",
  "name": "How to Analyze A\/B Tests Results?",
  "description": "What is A/B tests? Image that you are running an e-commerce platform which is an otter dolls specialty stores. You find that around 20% of users cancel the transactions in the very last step of the checkout flow (Fig. 1-a). To improve the checkout completion rate, you come up with an idea that adding an adorable otter image (Fig. 1-b), which assumes that image makes users have stronger desire to get the item.",
  "keywords": [
    
  ],
  "articleBody": "What is A/B tests? Image that you are running an e-commerce platform which is an otter dolls specialty stores. You find that around 20% of users cancel the transactions in the very last step of the checkout flow (Fig. 1-a). To improve the checkout completion rate, you come up with an idea that adding an adorable otter image (Fig. 1-b), which assumes that image makes users have stronger desire to get the item.\n Figure 1. Otter Store Checkout Page\n  How do you know an otter image can actually boost the purchase? The naive way is just add it and observe the checkout completion rate. However, it is difficult to make the judgement regardless of the observation. For example, the increment might be affected by a popular video documenting how new born otters open their eyes (Taipei zoo otter video). In other words, several factors influence the metric (i.e. checkout completion rate) you are observing.\nIt is necessary to make every conditions have equal impact (on average) across the variants if you want to make the correct decision. In fact, the concept is the same as “controlled experiments” we have heard many times. In industries, A/B tests is a more prevalent term to describe the process of conducting a controlled experiment. An A/B test (simply) consists of randomization, collecting data, and making statistical inference.\nTake the same example, first of all, you randomly split half of users to experience the view with the otter image while the other half experience the original version. Secondly, collect the users data until it is enough to make a valid inference. Finally, compare the metric of interest. This process is demonstrated in Fig. 2.\n Figure 2. Simplified A/B Test Flow\n  For further details, I highly recommend two articles that posted in Netflix TechBlog — “Decision Making at Netflix” and “What is an A/B Test?”. They explain the idea of the A/B test and the importance of the A/B test. To conclude this section, I would like to quote one inspiring sentence in “Decision Making at Netflix”: Making decisions is easy — what’s hard is making the right decision.\nFrequentism and Bayesianism The final step of the process of an A/B test (as shown in Fig. 2) is to compare the metric. Let’s say you observe that the checkout completion rate of the view with an otter image is 83% and the one of the current version is 81%. It is indecisive only based on these two numbers because the results are always possible just by chance. The gap between the observed metrics and conclusion is so-called statistical inference (Fig. 3).\n Figure 3. Statistical Inference\n  There are two common frameworks to perform the statistical inference — Frequenitsm and Bayesianism. In this section, I will introduce the notion of them without reaching too many mathematical parts.\nIf you had taken any level of statistics courses, the course may remind you of numerous confusing statistical terminology like p-values and confidence interval, which are the concept based on the Frequentism. Frequentist method is introduced by most of beginner level statistics course. Therefore, in fact you have already understood it if you just suffered from your painful memory of statistics course.\nIn the world of Frequentism, we assume that the reality is that there is no difference between the current and revised version (null hypothesis). In order to prove that the revised version is better, the strategy is to show that “it is highly unlikely to get the A/B test results if the null hypothesis is true”. The p-value is one of the computation of this strategy, showing that the probability of observing your A/B test results (or more extreme) given that the control and the treatment is equivalent in terms of the metric of interest. It is conventional to set the threshold of rejection the null hypothesis as 5% (significance level).\nSet the significance level to 5% for the difference of conversion rate between the control and treatment (i.e. 2% in our example), we can also create the other computation for this difference, 95% confidence interval, which says that if we repeat the A/B test, this interval will cover the true difference 95% of the time. If the 95% confidence interval doesn’t include 0, it shows that most of the time the treatment is better than the control. Hence, we can reject the null hypothesis that there is no difference between the control and the treatment.\nIn the world of Bayesianism, we use a distribution to describe the metric (or parameter). For example, we are 90% sure that the conversion rate is between 0.75 and 0.85 and 95% that it is between 0.7 and 0.9. Before starting an A/B test, you have an existing belief (distribution) of the conversion rate, which is called prior. During the process of collecting data, you continuously integrate new information and adjust your prior to form the posterior, the belief of the conversion rate after you see the data based on your prior.\nTo formulate the distribution of the conversion rate, Beta distribution describes this situation well. Fig. 4 demonstrates why it is suitable in the case of the conversion rate. It is easy to adjust the parameters to form a belief in terms of the value and intensity. For instance, the « color 1, and light color 1 » show that we believe that the conversion rate is around 0.8 while the « light color 1 » has less confidence. « color 2 » forms a totally different belief from the « color 1 ». If we have no idea about the conversion rate before running an A/B test, we can also construct a non informative belief as « color 3 ».\n Figure 4. Prior Distribution\n  Once forming the posterior of the control and the treatment, we can utilize it to develop a simulation, which generates more data to compute the probability of that the treatment is better than the control. Using the same simulated data, we can also compute the expected loss if we choose the wrong variant. The whole process is shown in Fig. 5.\n« FIG. 5 »\nAnalysis Tools In this section, I will introduce one very powerful python library to perform the analysis — Spotify Confidence. Spotify Confidence provides several powerful tools to easily and conveniently compute statistics like p-value and confidence interval, and moreover, create beautiful visualization of the A/B test results. Before we get started, I strongly recommend you to watch this video that explain the origin and the usage about Spotify Confidence library.\n  In the following content, I will use the same example in this article and show you how to use Spotify Confidence to analyze once you collect data. First of all, you have to import two required libraries, pandas and spotify_confidence. Also, to perform the analysis process, we create a clean and artificial data frame.\nimport pandas as pd import spotify_confidence as conf df = pd.DataFrame( { 'variant': ['control', 'treatment'], 'conversion': [1230, 1302], 'total': [1500, 1550] } ) df.head()  Figure 6. Exemplary Results\n  One of the most common statistical significane tests is two-sample Student t-tests. There are 6 input variables required to initiate a StudentsTTest class. It is very straightforward to set all inputs. Notice that since the outcome variable conversion is binary, we set the input numerator_sum_squares_column the same as numerator_column. Also, notice that the type of categorical_group_columns is a list, implying that we can compare the subgroups results.\nttest = conf.StudentsTTest( data_frame = df, numerator_column = 'conversion', numerator_sum_squares_column = 'conversion', denominator_column = 'total', categorical_group_columns = ['variant'], interval_size = 0.95, ) ttest.summary()  Figure 7. Results Summary\n  To see the difference between the control and the treatment, we simply use the difference method and input the groups to be compared. It returns a dataframe that contains calculated statistis like p-value and the upper/lower bound of the confidence interval.\nttest.difference( level_1 = 'control', level_2 = 'treatment' ) Besides statistics numbers, it is simple to visualize the results by the method difference_plot. It shows that the confidence interval includes the value 0, representing that the results do not have enough evidence to reject the null hypothesis in 5% significance level.\n Figure 8. Difference Summary\n  ttest.difference_plot( level_1 = 'control', level_2 = 'treatment' ).show()  Figure 9. Difference Plot\n  As introduced above, we can apply Beta distribution to form the belief in the case of conversion (Binomial). The inputs to initiate a class is almost same as Frequentist approach. You may notice that the values of ci_lower and ci_upper are different from what we found in t test. It is because Frequentist approach computes the confidence interval while Bayesian approach computes the credible interval.\nbayesian = conf.BetaBinomial( data_frame = df, numerator_column = 'conversion', denominator_column = 'total', categorical_group_columns = 'variant' ) bayesian.summary()  Figure 10. Results Summary\n  My favorite method of Spotify Confidence is that it can create a concise and easy to understand chartify plot. In this visualization, we realize the difference in terms of their distribution.\nbayesian.summary_plot().show()  Figure 11. Bayesian Summary\n  The difference method in BetaBinomial class simulates the results based on the distribution in Figure 11. and computes the difference, the probability that the treatment is better than the control, and the potential loss and gain across variants. Since the results are from simulation, we have to set the randomization seed for the reproductivity.\nconf.options.set_option('randomization_seed', 1) bayesian.difference( level_1 = 'control', level_2 = 'treatment' )  Figure 12. Bayesian Difference\n  The difference_plot method in Bayesian approach is very powerful. In this plot, we easily know the expected change from control to treatment and the probability that we make the wrong decision.\nbayesian.difference_plot( 'control', 'treatment' ).show()  Figure 13. Bayesian Difference Plot\n  Summary In this article, I introcude the concept and importance of A/B tests. To make a business decision from your A/B tests results, two statistical inference approaches are present in section Frequentism and Bayesianism. Finaaly, in order to perform the analysis, I demonstrate the basic usage of Spotify Confidence, a Python library for A/B test analysis.\n",
  "wordCount" : "1657",
  "inLanguage": "en",
  "datePublished": "2022-06-13T22:58:34+08:00",
  "dateModified": "2022-06-13T22:58:34+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://chunhouuu.github.io/posts/abtest-analysis/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from Tino",
    "logo": {
      "@type": "ImageObject",
      "url": "https://chunhouuu.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://chunhouuu.github.io/" accesskey="h" title="Notes from Tino (Alt + H)">Notes from Tino</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://chunhouuu.github.io/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://chunhouuu.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://chunhouuu.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      How to Analyze A/B Tests Results?
    </h1>
    <div class="post-meta"><span title='2022-06-13 22:58:34 +0800 CST'>June 13, 2022</span>&nbsp;·&nbsp;8 min

</div>
  </header> 
  <div class="post-content"><h3 id="what-is-ab-tests">What is A/B tests?<a hidden class="anchor" aria-hidden="true" href="#what-is-ab-tests">#</a></h3>
<p>Image that you are running an e-commerce platform which is an otter dolls specialty stores. You find that around 20% of users cancel the transactions in the very last step of the checkout flow (Fig. 1-a). To improve the checkout completion rate, you come up with an idea that adding an adorable otter image (Fig. 1-b), which assumes that image makes users have stronger desire to get the item.</p>
<figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/checkout.svg#center"
         alt="Figure 1. Otter Store Checkout Page"/> <figcaption>
            <p>Figure 1. Otter Store Checkout Page</p>
        </figcaption>
</figure>

<p>How do you know an otter image can actually boost the purchase? The naive way is just add it and observe the checkout completion rate. However, it is difficult to make the judgement regardless of the observation. For example, the increment might be affected by a popular video documenting how new born otters open their eyes (<a href="https://www.youtube.com/watch?v=v5xrLkMJUNo&amp;t=113s">Taipei zoo otter video</a>). In other words, several factors influence the metric (i.e. checkout completion rate) you are observing.</p>
<p>It is necessary to make every conditions have equal impact (on average) across the variants if you want to make the correct decision. In fact, the concept is the same as “controlled experiments” we have heard many times. In industries, A/B tests is a more prevalent term to describe the process of conducting a controlled experiment. An A/B test (simply) consists of randomization, collecting data, and making statistical inference.</p>
<p>Take the same example, first of all, you randomly split half of users to experience the view with the otter image while the other half experience the original version. Secondly, collect the users data until it is enough to make a valid inference. Finally, compare the metric of interest. This process is demonstrated in Fig. 2.</p>
<figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/simplified_abtest_flow.svg#center"
         alt="Figure 2. Simplified A/B Test Flow"/> <figcaption>
            <p>Figure 2. Simplified A/B Test Flow</p>
        </figcaption>
</figure>

<p>For further details, I highly recommend two articles that posted in Netflix TechBlog — “Decision Making at Netflix” and “What is an A/B Test?”. They explain the idea of the A/B test and the importance of the A/B test. To conclude this section, I would like to quote one inspiring sentence in “Decision Making at Netflix”: Making decisions is easy — what’s hard is making the right decision.</p>
<h3 id="frequentism-and-bayesianism">Frequentism and Bayesianism<a hidden class="anchor" aria-hidden="true" href="#frequentism-and-bayesianism">#</a></h3>
<p>The final step of the process of an A/B test (as shown in Fig. 2) is to compare the metric. Let’s say you observe that the checkout completion rate of the view with an otter image is 83% and the one of the current version is 81%. It is indecisive only based on these two numbers because the results are always possible just by chance. The gap between the observed metrics and conclusion is so-called statistical inference (Fig. 3).</p>
<figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/statistical_inference.svg#center"
         alt="Figure 3. Statistical Inference"/> <figcaption>
            <p>Figure 3. Statistical Inference</p>
        </figcaption>
</figure>

<p>There are two common frameworks to perform the statistical inference — Frequenitsm and Bayesianism. In this section, I will introduce the notion of them without reaching too many mathematical parts.</p>
<p>If you had taken any level of statistics courses, the course may remind you of numerous confusing statistical terminology like p-values and confidence interval, which are the concept based on the Frequentism. Frequentist method is introduced by most of beginner level statistics course. Therefore, in fact you have already understood it if you just suffered from your painful memory of statistics course.</p>
<p>In the world of Frequentism, we assume that the reality is that there is no difference between the current and revised version (null hypothesis). In order to prove that the revised version is better, the strategy is to show that “it is highly unlikely to get the A/B test results if the null hypothesis is true”. The p-value is one of the computation of this strategy, showing that the probability of observing your A/B test results (or more extreme) given that the control and the treatment is equivalent in terms of the metric of interest. It is conventional to set the threshold of rejection the null hypothesis as 5% (significance level).</p>
<p>Set the significance level to 5% for the difference of conversion rate between the control and treatment (i.e. 2% in our example), we can also create the other computation for this difference, 95% confidence interval, which says that if we repeat the A/B test, this interval will cover the true difference 95% of the time. If the 95% confidence interval doesn’t include 0, it shows that most of the time the treatment is better than the control. Hence, we can reject the null hypothesis that there is no difference between the control and the treatment.</p>
<p>In the world of Bayesianism, we use a distribution to describe the metric (or parameter). For example, we are 90% sure that the conversion rate is between 0.75 and 0.85 and 95% that it is between 0.7 and 0.9. Before starting an A/B test, you have an existing belief (distribution) of the conversion rate, which is called prior. During the process of collecting data, you continuously integrate new information and adjust your prior to form the posterior, the belief of the conversion rate after you see the data based on your prior.</p>
<p>To formulate the distribution of the conversion rate, Beta distribution describes this situation well. Fig. 4 demonstrates why it is suitable in the case of the conversion rate. It is easy to adjust the parameters to form a belief in terms of the value and intensity. For instance, the &laquo; color 1, and light color 1 &raquo; show that we believe that the conversion rate is around 0.8 while the &laquo; light color 1 &raquo; has less confidence. &laquo; color 2 &raquo;  forms a totally different belief from the &laquo; color 1 &raquo;. If we have no idea about the conversion rate before running an A/B test, we can also construct a non informative belief as &laquo; color 3 &raquo;.</p>
<figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/prior_dist.svg#center"
         alt="Figure 4. Prior Distribution"/> <figcaption>
            <p>Figure 4. Prior Distribution</p>
        </figcaption>
</figure>

<p>Once forming the posterior of the control and the treatment, we can utilize it to develop a simulation, which generates more data to compute the probability of that the treatment is better than the control. Using the same simulated data, we can also compute the expected loss if we choose the wrong variant. The whole process is shown in Fig. 5.</p>
<p>&laquo; FIG. 5 &raquo;</p>
<h3 id="analysis-tools">Analysis Tools<a hidden class="anchor" aria-hidden="true" href="#analysis-tools">#</a></h3>
<p>In this section, I will introduce one very powerful python library to perform the analysis — Spotify Confidence. Spotify Confidence provides several powerful tools to easily and conveniently compute statistics like p-value and confidence interval, and moreover, create beautiful visualization of the A/B test results. Before we get started, I strongly recommend you to watch this video that explain the origin and the usage about Spotify Confidence library.</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/qv6Rn8uQCLY" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<p>In the following content, I will use the same example in this article and show you how to use Spotify Confidence to analyze once you collect data. First of all, you have to import two required libraries, pandas and spotify_confidence. Also, to perform the analysis process, we create a clean and artificial data frame.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">spotify_confidence</span> <span class="k">as</span> <span class="nn">conf</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;variant&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;control&#39;</span><span class="p">,</span> <span class="s1">&#39;treatment&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;conversion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1230</span><span class="p">,</span> <span class="mi">1302</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;total&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1500</span><span class="p">,</span> <span class="mi">1550</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/sample_df.png#center"
         alt="Figure 6. Exemplary Results"/> <figcaption>
            <p>Figure 6. Exemplary Results</p>
        </figcaption>
</figure>

<p>One of the most common statistical significane tests is two-sample Student t-tests. There are 6 input variables required to initiate a StudentsTTest class. It is very straightforward to set all inputs. Notice that since the outcome variable conversion is binary, we set the input numerator_sum_squares_column the same as numerator_column. Also, notice that the type of categorical_group_columns is a list, implying that we can compare the subgroups results.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">ttest</span> <span class="o">=</span> <span class="n">conf</span><span class="o">.</span><span class="n">StudentsTTest</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">data_frame</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">numerator_column</span> <span class="o">=</span> <span class="s1">&#39;conversion&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">numerator_sum_squares_column</span> <span class="o">=</span> <span class="s1">&#39;conversion&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">denominator_column</span> <span class="o">=</span> <span class="s1">&#39;total&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">categorical_group_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;variant&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">interval_size</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">ttest</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/ttest_summary.png#center"
         alt="Figure 7. Results Summary"/> <figcaption>
            <p>Figure 7. Results Summary</p>
        </figcaption>
</figure>

<p>To see the difference between the control and the treatment, we simply use the difference method and input the groups to be compared. It returns a dataframe that contains calculated statistis like p-value and the upper/lower bound of the confidence interval.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">ttest</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">level_1</span> <span class="o">=</span> <span class="s1">&#39;control&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">level_2</span> <span class="o">=</span> <span class="s1">&#39;treatment&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p>Besides statistics numbers, it is simple to visualize the results by the method difference_plot. It shows that the confidence interval includes the value 0, representing that the results do not have enough evidence to reject the null hypothesis in 5% significance level.</p>
<figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/ttest_diff.png#center"
         alt="Figure 8. Difference Summary"/> <figcaption>
            <p>Figure 8. Difference Summary</p>
        </figcaption>
</figure>

<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">ttest</span><span class="o">.</span><span class="n">difference_plot</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">level_1</span> <span class="o">=</span> <span class="s1">&#39;control&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">level_2</span> <span class="o">=</span> <span class="s1">&#39;treatment&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/ttest_diff_plot.png#center"
         alt="Figure 9. Difference Plot"/> <figcaption>
            <p>Figure 9. Difference Plot</p>
        </figcaption>
</figure>

<p>As introduced above, we can apply Beta distribution to form the belief in the case of conversion (Binomial). The inputs to initiate a class is almost same as Frequentist approach. You may notice that the values of ci_lower and ci_upper are different from what we found in t test. It is because Frequentist approach computes the confidence interval while Bayesian approach computes the credible interval.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">bayesian</span> <span class="o">=</span> <span class="n">conf</span><span class="o">.</span><span class="n">BetaBinomial</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">data_frame</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">numerator_column</span> <span class="o">=</span> <span class="s1">&#39;conversion&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">denominator_column</span> <span class="o">=</span> <span class="s1">&#39;total&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">categorical_group_columns</span> <span class="o">=</span> <span class="s1">&#39;variant&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">bayesian</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/bayesian_summary.png#center"
         alt="Figure 10. Results Summary"/> <figcaption>
            <p>Figure 10. Results Summary</p>
        </figcaption>
</figure>

<p>My favorite method of Spotify Confidence is that it can create a concise and easy to understand <a href="https://github.com/spotify/chartify">chartify</a> plot. In this visualization, we realize the difference in terms of their distribution.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">bayesian</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/bayesian_summary_plot.png#center"
         alt="Figure 11. Bayesian Summary"/> <figcaption>
            <p>Figure 11. Bayesian Summary</p>
        </figcaption>
</figure>

<p>The difference method in BetaBinomial class simulates the results based on the distribution in Figure 11. and computes the difference, the probability that the treatment is better than the control, and the potential loss and gain across variants. Since the results are from simulation, we have to set the randomization seed for the reproductivity.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">conf</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;randomization_seed&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">bayesian</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">level_1</span> <span class="o">=</span> <span class="s1">&#39;control&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">    <span class="n">level_2</span> <span class="o">=</span> <span class="s1">&#39;treatment&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/bayesian_diff.png#center"
         alt="Figure 12. Bayesian Difference"/> <figcaption>
            <p>Figure 12. Bayesian Difference</p>
        </figcaption>
</figure>

<p>The difference_plot method in Bayesian approach is very powerful. In this plot, we easily know the expected change from control to treatment and the probability that we make the wrong decision.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">bayesian</span><span class="o">.</span><span class="n">difference_plot</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;control&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;treatment&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="/posts/assets/images/bayesian_diff_plot.png#center"
         alt="Figure 13. Bayesian Difference Plot"/> <figcaption>
            <p>Figure 13. Bayesian Difference Plot</p>
        </figcaption>
</figure>

<h3 id="summary">Summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h3>
<p>In this article, I introcude the concept and importance of A/B tests. To make a business decision from your A/B tests results, two statistical inference approaches are present in section Frequentism and Bayesianism. Finaaly, in order to perform the analysis, I demonstrate the basic usage of Spotify Confidence, a Python library for A/B test analysis.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://chunhouuu.github.io/">Notes from Tino</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
